package com.example.batch;

import org.springframework.batch.core.configuration.annotation.EnableBatchProcessing;
import org.springframework.batch.core.configuration.annotation.JobBuilderFactory;
import org.springframework.batch.core.configuration.annotation.StepBuilderFactory;
import org.springframework.batch.core.job.SimpleJobBuilder;
import org.springframework.batch.core.job.builder.JobBuilder;
import org.springframework.batch.core.launch.support.RunIdIncrementer;
import org.springframework.batch.core.step.builder.StepBuilder;
import org.springframework.batch.item.ItemProcessor;
import org.springframework.batch.item.ItemWriter;
import org.springframework.batch.item.support.ListItemReader;
import org.springframework.batch.item.support.IteratorItemReader;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import software.amazon.awssdk.core.ResponseBytes;
import software.amazon.awssdk.services.s3.S3Client;
import software.amazon.awssdk.services.s3.model.GetObjectRequest;
import software.amazon.awssdk.services.s3.model.GetObjectResponse;
import software.amazon.awssdk.services.s3.model.S3Object;

import java.nio.file.Paths;
import java.nio.charset.StandardCharsets;
import java.time.Instant;
import java.time.temporal.ChronoUnit;
import java.util.List;
import java.util.stream.Collectors;
import java.util.stream.IntStream;

@Configuration
@EnableBatchProcessing
public class BatchConfig {
    
    private final JobBuilderFactory jobBuilderFactory;
    private final StepBuilderFactory stepBuilderFactory;
    private final S3Client s3Client;
    
    public BatchConfig(JobBuilderFactory jobBuilderFactory, StepBuilderFactory stepBuilderFactory, S3Client s3Client) {
        this.jobBuilderFactory = jobBuilderFactory;
        this.stepBuilderFactory = stepBuilderFactory;
        this.s3Client = s3Client;
    }
    
    @Bean
    public IteratorItemReader<List<String>> s3ObjectReader() {
        List<String> objectKeys = s3Client.listObjectsV2(req -> req.bucket("your-bucket-name")).contents()
                .stream()
                .filter(obj -> obj.lastModified().isAfter(Instant.now().minus(24, ChronoUnit.HOURS)))
                .map(S3Object::key)
                .collect(Collectors.toList());
        
        List<List<String>> chunks = IntStream.range(0, (objectKeys.size() + 9) / 10)
                .mapToObj(i -> objectKeys.subList(i * 10, Math.min(objectKeys.size(), (i + 1) * 10)))
                .collect(Collectors.toList());
        
        return new IteratorItemReader<>(chunks.iterator());
    }
    
    @Bean
    public ItemProcessor<List<String>, List<String>> processor() {
        return objectKeys -> objectKeys.stream().map(key -> {
            GetObjectRequest getObjectRequest = GetObjectRequest.builder()
                    .bucket("your-bucket-name")
                    .key(key)
                    .build();
            
            ResponseBytes<GetObjectResponse> objectBytes = s3Client.getObjectAsBytes(getObjectRequest);
            String content = new String(objectBytes.asByteArray(), StandardCharsets.UTF_8);
            
            return "Processed: " + key + " - Content: " + content;
        }).collect(Collectors.toList());
    }
    
    @Bean
    public ItemWriter<List<String>> writer() {
        return items -> {
            for (List<String> batch : items) {
                java.nio.file.Files.write(Paths.get("output.csv"), batch);
            }
        };
    }
    
    @Bean
    public org.springframework.batch.core.Step step1() {
        return stepBuilderFactory.get("step1")
                .<List<String>, List<String>>chunk(1)
                .reader(s3ObjectReader())
                .processor(processor())
                .writer(writer())
                .build();
    }
    
    @Bean
    public org.springframework.batch.core.Job job() {
        return jobBuilderFactory.get("s3Job")
                .incrementer(new RunIdIncrementer())
                .start(step1())
                .build();
    }
}
